Bootstrap: docker
From: pytorch/pytorch:2.8.0-cuda12.9-cudnn9-devel
# From: pytorch/pytorch:2.4.1-cuda12.4-cudnn9-devel

%post
    # Install basics
    apt-get update && apt-get install -y build-essential cmake git python3 python3-pip curl ca-certificates
    ln -s /usr/bin/python3 /usr/bin/python
    
    # Install uv
    curl -LsSf https://astral.sh/uv/install.sh | sh
    
    # Install all required packages
    uv pip install -u vllm

    # For llama-cpp-python with CMAKE_ARGS
    # We need to ensure CMAKE_ARGS is set for the uv command.
    # The --config-settings approach is generally more robust for uv/pip when dealing with build flags.
    uv pip install --no-cache-dir llama-cpp-python --config-settings="cmake.args=-DGGML_CUDA=on"

%files
    # Copy requirements.txt into the container
    requirements.txt /app/

%labels
    Author alban.bornet@unige.ch
    Version 0.1
    Description "Llama-cpp-python container with uv"